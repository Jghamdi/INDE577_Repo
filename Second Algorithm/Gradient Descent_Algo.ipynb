{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Linear Regression with Single Neuron and Gradient Descent\n",
    "\n",
    "In this notebook, we delve into the implementation of a single neuron model coupled with the gradient descent algorithm to tackle the **linear regression problem**. The primary aim is to provide a hands-on exploration of fundamental concepts in linear regression applied to the Palmer Penguin species data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **Dataset Description:** We utilize the Palmer Penguin dataset, which contains comprehensive measurements of penguin species attributes.\n",
    "2. **Model Implementation:** The single neuron model, augmented with a constant activation function, forms the basis for our linear regression approach.\n",
    "3. **Gradient Descent:** We employ the gradient descent algorithm to iteratively optimize model parameters and minimize the error between predicted and actual values.\n",
    "4. **Visualization:** Through visualizations, we illustrate the linear regression results, including the learned regression line and its alignment with the penguin species data.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard data science libraries for visualization and data manipulation.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Import a helpful function for plotting decision boundaries.\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# Set the Seaborn theme for aesthetic visualizations.\n",
    "sns.set_theme()\n",
    "\n",
    "# Load the Palmer Penguin dataset from the provided CSV file.\n",
    "df = pd.read_csv('palmer_penguins.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Linear Regression Overview\n",
    "\n",
    "Linear regression is a widely used technique that assumes a linear relationship between the independent variables (features) and the dependent variable (target). In our case, we assume that the optimal target function for penguin species data is approximately linear.\n",
    "\n",
    "### Example: Visualizing Linear Relationship\n",
    "\n",
    "To illustrate the concept of linear regression, let's consider an example using the Palmer Penguin dataset. We will examine the relationship between the bill length and bill depth of Chinstrap penguins. This can be verified by visualizing the data. We can examine the figure generated by running the following code in the cell below.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and set the Seaborn theme.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "# Load the Palmer Penguin dataset.\n",
    "df = pd.read_csv('palmer_penguins.csv')\n",
    "\n",
    "# Select all rows for the 'Chinstrap' species.\n",
    "target_data = df[df['species'] == 'Chinstrap'][['bill_length_mm', 'bill_depth_mm']]\n",
    "\n",
    "# Plot the selected data points for 'Chinstrap' species based on bill measurements.\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(target_data['bill_length_mm'], \n",
    "            target_data['bill_depth_mm'], \n",
    "            color='lightblue',  \n",
    "            label='Chinstrap Penguins')\n",
    "plt.xlabel('Bill Length (mm)', fontsize=15)\n",
    "plt.ylabel('Bill Depth (mm)', fontsize=15)\n",
    "plt.title('Chinstrap Penguin Regression Data', fontsize=18)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### CustomNeuron Class\n",
    "\n",
    "The `CustomNeuron` class encapsulates the functionality of a single artificial neuron. Below are the details of the class attributes and methods.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNeuron(object):\n",
    "    \"\"\"\n",
    "    A class used to represent a single artificial neuron. \n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    activation_function : function\n",
    "        The activation function applied to the preactivation linear combination.\n",
    "\n",
    "    weights_bias_ : numpy.ndarray\n",
    "        The weights and bias of the single neuron. The last entry being the bias. \n",
    "        This attribute is created when the fit method is called.\n",
    "\n",
    "    errors_: list\n",
    "        A list containing the mean squared error computed after each iteration \n",
    "        of stochastic gradient descent per epoch. \n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __init__(self, activation_function)\n",
    "        Initializes the CustomNeuron object with the provided activation function.\n",
    "\n",
    "    fit(self, X, y, alpha=0.005, epochs=50)\n",
    "        Iterates the stochastic gradient descent algorithm through each sample \n",
    "        a total of epochs number of times with learning rate alpha. The data \n",
    "        used consists of feature vectors X and associated labels y. \n",
    "\n",
    "    predict(self, X)\n",
    "        Uses the weights and bias, the feature vectors in X, and the \n",
    "        activation_function to make predictions.\n",
    "    \"\"\"\n",
    "    def __init__(self, activation_function):\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def fit(self, X, y, alpha=0.005, epochs=50):\n",
    "        self.weights_bias_ = np.random.rand(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "        N = X.shape[0]\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                error = (self.predict(xi) - target)\n",
    "                self.weights_bias_[:-1] -= alpha * error * xi\n",
    "                self.weights_bias_[-1] -= alpha * error\n",
    "                errors += 0.5 * (error ** 2)\n",
    "            self.errors_.append(errors / N)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        preactivation = np.dot(X, self.weights_bias_[:-1]) + self.weights_bias_[-1]\n",
    "        return self.activation_function(preactivation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "Before training our custom `CustomNeuron` model, we need to format our data appropriately. The following steps outline the data formatting process:\n",
    "\n",
    "## Quick Data Formatting\n",
    "\n",
    "To prepare our data for training, we first need to ensure it is properly formatted. Follow the steps outlined below:\n",
    "\n",
    "1. **Convert to NumPy Arrays:** The first step involves converting the relevant columns of the Palmer Penguin dataset into NumPy arrays. For example, we convert the 'bill_length_mm' column into a NumPy array.\n",
    "\n",
    "2. **Reshape Feature Vectors:** Single-entry feature vectors must be reshaped using the `reshape(-1, 1)` method. This ensures the correct dimensions required for vector and matrix multiplications.\n",
    "\n",
    "3. **Convert Labels to NumPy Arrays:** Next, we convert the labels (e.g., 'bill_depth_mm') into NumPy arrays for further processing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sepal length values from the DataFrame and reshape to a 2D array.\n",
    "X = target_data['bill_length_mm'].values\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "# Extract sepal width values from the DataFrame.\n",
    "y = target_data['bill_depth_mm'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the selected features 'bill_length_mm' against 'bill_depth_mm' for Adelie penguins.\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X, y, color='lightseagreen', label='ChinstrapPenguins')\n",
    "plt.xlabel('Bill Length (mm)', fontsize=15)\n",
    "plt.ylabel('Bill Depth (mm)', fontsize=15)\n",
    "plt.title('Adelie Penguin Regression Data', fontsize=18)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_activation(z):\n",
    "    return z\n",
    "\n",
    "node = SingleNeuron(constant_activation)\n",
    "node.train(X, y, alpha = 0.0001, epochs = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the domain for prediction using the feature 'bill_length_mm'.\n",
    "domain = np.linspace(np.min(X) - 0.5, np.max(X) + 0.5, 100)\n",
    "\n",
    "# Plotting the data points and the regression line for 'Chinstrap' penguins.\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X, y, color='lightseagreen', label='Chinstrap Penguins')\n",
    "plt.plot(domain, node.predict(domain.reshape(-1, 1)))\n",
    "plt.xlabel('Bill Length (mm)', fontsize=15)\n",
    "plt.ylabel('Bill Depth (mm)', fontsize=15)\n",
    "plt.title('Chinstrap Penguin Regression Data', fontsize=18)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "plt.plot(range(1, len(node.errors_) + 1), \n",
    "         node.errors_,\n",
    "         marker = \"o\",\n",
    "         label = \"MSE\")\n",
    "plt.xlabel(\"epochs\", fontsize = 15)\n",
    "plt.ylabel(\"MSE\", fontsize = 15)\n",
    "plt.xticks(range(1, len(node.errors_) + 1))\n",
    "plt.legend(fontsize = 15)\n",
    "plt.title(\"MSE Error at Each Epoch During Training\", fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = SingleNeuron(constant_activation)\n",
    "node.train(X, y, alpha = .0001, epochs = 50)   # Train over 50 epochs.\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,10))\n",
    "\n",
    "ax1.scatter(X, y, color = \"lightseagreen\")\n",
    "ax1.plot(domain, node.predict(domain.reshape(-1, 1)))\n",
    "ax1.set_xlabel(\"sepal length [cm]\", fontsize = 15)\n",
    "ax1.set_ylabel(\"sepal width [cm]\", fontsize = 15)\n",
    "ax1.set_title(\"Setosa Regression Data\", fontsize = 18)\n",
    "\n",
    "ax2.plot(range(1, len(node.errors_) + 1), \n",
    "         node.errors_,\n",
    "         marker = \"o\",\n",
    "         label = \"MSE\")\n",
    "ax2.set_xlabel(\"epochs\")\n",
    "ax2.set_ylabel(\"MSE\")\n",
    "ax2.set_xticks(range(1, len(node.errors_) + 1, 5))\n",
    "ax2.legend(fontsize = 10)\n",
    "ax2.set_title(\"MSE Error at Each Epoch During Training\", fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible choices of learning rate \n",
    "alphas = [0.01, 0.05, 0.07, 0.09]\n",
    "\n",
    "domain = np.linspace(np.min(X) - .5, np.max(X) + .5, 100)\n",
    "\n",
    "# Call the subplots method for plotting a grid of figures\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10,10))\n",
    "\n",
    "# Loop over the axs and alpha values\n",
    "for ax, alpha in zip(axs.flat, alphas):\n",
    "    node = SingleNeuron(constant_activation)\n",
    "    node.train(X, y, alpha = alpha, epochs = 1_000)\n",
    "    ax.plot(domain, node.predict(domain.reshape(-1, 1)))\n",
    "    ax.scatter(X, y, color = \"lightseagreen\")\n",
    "    ax.set_title(f\"alpha = {alpha}\", fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
